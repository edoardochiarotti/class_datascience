{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e46e6b8",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/edoardochiarotti/class_datascience/blob/main/2023/05_Mean-Model/Resources/05_Mean_model_exercises_solutions.ipynb\" target=\"_blank\" rel=\"noopener\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6e4a6e",
   "metadata": {},
   "source": [
    "# The Mean Model - Exercises with Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bc2a66",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgflip.com/82uqjd.jpg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4413cca1",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# PACKAGES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import statistics as st\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# FUNCTIONS FROM PACKAGES\n",
    "from numpy.linalg import inv\n",
    "\n",
    "# SEABORN THEME\n",
    "scale = 0.4\n",
    "W = 16*scale\n",
    "H = 9*scale\n",
    "sns.set(rc = {'figure.figsize':(W,H)})\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c28d370",
   "metadata": {},
   "source": [
    "Main references:\n",
    "- For the part on the functions for the sample mean and variance, we took inspiration from the amazing class on [Multiple Equation Estimation](https://www.fionaburlig.com/teaching/are212) by Fiona Burlig (with R) at UC Berkeley.\n",
    "- For a refresher on matrixes and matrixes in Python, see the [Notebook on matrixes](https://github.com/edoardochiarotti/class_datascience/blob/main/2023/05_Mean-Model/Resources/05_Matrixes.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9037ff81",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Content\n",
    "- [Exercise 1: Load data](#Exercise-1:-Load-data)\n",
    "- [Exercise 2: Debugging the Mean Estimator](#Exercise-2:-Debugging-the-Mean-Estimator)\n",
    "- [Exercise 3: Write Nice Functions for your Estimators](#Exercise-3:-Write-Nice-Functions-for-your-Estimators)\n",
    "- [Exercise 4: Statistical Test with the Sample Mean](#Exercise-4:-Statistical-Test-with-the-Sample-Mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791ed010",
   "metadata": {},
   "source": [
    "## Exercise 1: Load data <a name=\"Exercise-1:-Load-data\"></a>\n",
    "- Let's now use **Python** to write down the functions for the sample-mean and sample-variance estimators using matrix notation.\n",
    "- We'll test these functions on data from the **QoG Environmental Indicators dataset (QoG-EI)** (Povitkina, Marina, Natalia Alvarado Pachon & Cem Mert Dalli. 2021). The Quality of Government Environmental Indicators Dataset, version Sep21 (University of Gothenburg: [The Quality of Government Institute](https://www.gu.se/en/quality-government)), is a compilation of indicators measuring countries' environmental performance over time, including the presence and stringency of environmental policies, environmental outcomes (emissions, deforestation, etc.), and public opinion on the environment. Codebook and data are available [here](https://www.gu.se/en/quality-government/qog-data/data-downloads/environmental-indicators-dataset).\n",
    "- Note that we could test theste functions also on generated data, but it's nicer to test them on real-life data.\n",
    "- Get the QoG dataset using this link `https://www.qogdata.pol.gu.se/data/qog_ei_sept21.xlsx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3f83da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ...\n",
    "\n",
    "# get data\n",
    "link = \"https://www.qogdata.pol.gu.se/data/qog_ei_sept21.xlsx\"\n",
    "df_qog = pd.read_excel(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf91a053",
   "metadata": {},
   "source": [
    "- For this exercise we'll use the sample mean to estimate the mean of **CO2 emissions per capita**. In QoG, the variable for total CO2 emissions per capita is `edgar_co2pc`.\n",
    "- Create a subset of the dataset you have downloaded with only the variables `ccodealp`, `year` and `edgar_co2pc`, and display it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08b523ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ccodealp</th>\n",
       "      <th>year</th>\n",
       "      <th>edgar_co2pc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>1946</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>1947</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>1948</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG</td>\n",
       "      <td>1949</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>1950</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11717</th>\n",
       "      <td>VDR</td>\n",
       "      <td>1972</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11718</th>\n",
       "      <td>VDR</td>\n",
       "      <td>1973</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11719</th>\n",
       "      <td>VDR</td>\n",
       "      <td>1974</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11720</th>\n",
       "      <td>VDR</td>\n",
       "      <td>1975</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11721</th>\n",
       "      <td>VDR</td>\n",
       "      <td>1976</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11722 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ccodealp  year  edgar_co2pc\n",
       "0          AFG  1946          NaN\n",
       "1          AFG  1947          NaN\n",
       "2          AFG  1948          NaN\n",
       "3          AFG  1949          NaN\n",
       "4          AFG  1950          NaN\n",
       "...        ...   ...          ...\n",
       "11717      VDR  1972          NaN\n",
       "11718      VDR  1973          NaN\n",
       "11719      VDR  1974          NaN\n",
       "11720      VDR  1975          NaN\n",
       "11721      VDR  1976          NaN\n",
       "\n",
       "[11722 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here ...\n",
    "\n",
    "# indexes\n",
    "indexes = [\"ccodealp\",\"year\"]\n",
    "\n",
    "# CO2 variables\n",
    "variabs_co2 = [\"edgar_co2pc\"]\n",
    "\n",
    "# subset\n",
    "df_qog_sub = df_qog.loc[:,np.append(indexes,variabs_co2)]\n",
    "df_qog_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8567358f",
   "metadata": {},
   "source": [
    "- As this is a panel dataset and we want to start simple\n",
    "    - Collapse the subset database into **cross section** of countries by taking the mean of all variables by country. When you do this, keep the variable `ccodealp` as a variable, and not as an index of the dataframe.\n",
    "    - Drop all missing values, as our sample mean estimator will work only on a clean dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4637c0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ccodealp</th>\n",
       "      <th>edgar_co2pc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>0.161829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGO</td>\n",
       "      <td>1.093760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALB</td>\n",
       "      <td>1.800099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARE</td>\n",
       "      <td>35.023444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARG</td>\n",
       "      <td>3.965821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>WSM</td>\n",
       "      <td>0.631124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>YEM</td>\n",
       "      <td>0.804577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>ZAF</td>\n",
       "      <td>8.327993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>ZMB</td>\n",
       "      <td>0.423897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>1.210966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ccodealp  edgar_co2pc\n",
       "0        AFG     0.161829\n",
       "1        AGO     1.093760\n",
       "2        ALB     1.800099\n",
       "3        ARE    35.023444\n",
       "4        ARG     3.965821\n",
       "..       ...          ...\n",
       "173      WSM     0.631124\n",
       "174      YEM     0.804577\n",
       "175      ZAF     8.327993\n",
       "176      ZMB     0.423897\n",
       "177      ZWE     1.210966\n",
       "\n",
       "[178 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here ...\n",
    "\n",
    "# make cross section\n",
    "df = df_qog_sub.groupby(\"ccodealp\")[variabs_co2].mean().reset_index().dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a82e43f",
   "metadata": {},
   "source": [
    "- You should have obtained a dataframe with 178 rows, i.e., 178 countries.\n",
    "- Now we want to estimate the mean of our variable of interest emissions per capita `edgar_co2pc`. Let's do the **usual reasoning** shall we? Our unit for this analysis are the countries. There is a population of countries in the world with their emissions per capita, represented by a normal probability distribution of emissions with mean $\\beta$ and variance $\\sigma^2$ . We cannot work with the population, but we can work only with a sample of emissions for 178 countries we have at hand (which is the realization of a random sample). This sample is just a representation of the population of all countries in the world, which amounts to 196 countries (yeah, in this case our sample is very close to the full population, but still it's not the full population).\n",
    "- The sample-mean estimator is a good estimator for the average emission $\\beta$. As mentioned, if we define a N-dimensional vector of 1s $\\boldsymbol{x}=(1,...,1)'$, the sample-mean estimator can be expressed as $\\hat{\\beta}= (\\boldsymbol{x}'\\boldsymbol{x})^{-1}(\\boldsymbol{x}'\\boldsymbol{y})$. \n",
    "- So let's add this **vector of ones** to our dataset. Consider the collapsed dataframe you have obtained in the former question and add a column of ones, and display the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca98585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ...\n",
    "\n",
    "# put ones into data\n",
    "df[\"ones\"] = 1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182bec48",
   "metadata": {},
   "source": [
    "## Exercise 2: Debugging the Mean Estimator <a name=\"Exercise-2:-Debugging-the-Mean-Estimator\"></a>\n",
    "- We can now write our **function for the sample mean estimator**. As we need to work with matrixes, the first thing to do is to convert panda data into numpy arrays (what Python uses for matrixes). Once the conversion is done, we can write the formula of our estimator by using the functions for matrix operations (multiplication, transpose, inverse) that we have learned in Python.\n",
    "- Let's give it a first try with a function that takes as arguments the dataframe, the name of our variable of interest (y) and the name of our single regressor, which is the vector of ones (x).\n",
    "- I report here below an example of this function. By reading the lines you should be able to understand what this does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d317463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sample mean function\n",
    "def sample_mean_estimator(data, y, x):\n",
    "    \n",
    "    \"\"\" My Sample Mean Function \"\"\"\n",
    "    \n",
    "    # store in matrixes\n",
    "    ydata = data.loc[:,y].to_numpy()\n",
    "    xdata = data.loc[:,x].to_numpy()\n",
    "\n",
    "    # get sample mean\n",
    "    beta_hat = (inv(xdata.T @ xdata)) @ (xdata.T @ ydata)\n",
    "\n",
    "    # return\n",
    "    return float(beta_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aae52d",
   "metadata": {},
   "source": [
    "- Use this function to obtain the sample mean of the variable `edgar_co2pc` (remember you also have the argument `x` to fill in ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0cf0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ...\n",
    "\n",
    "# try function\n",
    "sample_mean_estimator(data = df, y = \"edgar_co2pc\", x = \"ones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5dbd19",
   "metadata": {},
   "source": [
    "- The function should give you the error \"LinAlgError\", so there must be something wrong with our linear algebra? In addition, the error says `0-dimensional array given. Array must be at least two-dimensional`. Possibly we are feeding a function with a 0-dimensional array, though this function wants an array that is at least two-dimensional. \n",
    "- Debug the `sample_mean_estimator(data, y, x)` function, i.e. find the bug (find the line of code that gives the error). Tips:\n",
    "    - Use as many cells as you need (here below I have just put one, you can add more)\n",
    "    - As first step, you should store the arguments you have used for the function as objects in the general environment in which you are working. Translated, that means store `df` as `data`, `\"edgar_co2pc\"` as `y` and `\"ones\"` as `x`. Then, copy the body of your function and re-run.\n",
    "    - The bug has something to do with how Python applies certain operations to scalars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0dfe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ...\n",
    "\n",
    "# debug\n",
    "data = df\n",
    "y = \"edgar_co2pc\"\n",
    "x = \"ones\"\n",
    "\n",
    "# store in matrixes\n",
    "ydata = data.loc[:,y].to_numpy()\n",
    "xdata = data.loc[:,x].to_numpy()\n",
    "\n",
    "# get sample mean\n",
    "beta_hat = (inv(xdata.T @ xdata)) @ (xdata.T @ ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0fd88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata.T @ xdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cda43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv(xdata.T @ xdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d464f48d",
   "metadata": {},
   "source": [
    "- Find a solution for this bug and update the function `sample_mean_estimator` with this solution. Tips:\n",
    "    - There are more solutions, for example one has to do with the syntax `[[]]`, and another one has to do with the function `np.atleast_2d`. \n",
    "    - The second one is the more general one and the one to focus on.\n",
    "    - The update should be a chunk of code between the chunks `# store in matrixes` and `# get sample mean`.\n",
    "    - Feel free to use as many cells as you need.\n",
    "- Run the function and compute the sample average of CO2 emissions per capita. How much is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c074a71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ...\n",
    "solution = np.array([[xdata.T @ xdata]])\n",
    "print(solution.shape)\n",
    "print(inv(solution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c9d8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define better sample mean function\n",
    "def sample_mean_estimator(data, y, x):\n",
    "    \n",
    "    \"\"\" My Sample Mean Function \"\"\"\n",
    "    \n",
    "    # store in matrixes\n",
    "    ydata = data.loc[:,y].to_numpy()\n",
    "    xdata = data.loc[:,x].to_numpy()\n",
    "    \n",
    "    # make column vectors for arrays with less than 2 dimensions\n",
    "    if len(ydata.shape) == 1:\n",
    "        ydata = np.atleast_2d(ydata).T\n",
    "    if len(xdata.shape) == 1:\n",
    "        xdata = np.atleast_2d(xdata).T\n",
    "\n",
    "    # get sample mean\n",
    "    beta_hat = (inv(xdata.T @ xdata)) @ (xdata.T @ ydata)\n",
    "\n",
    "    # return\n",
    "    return float(beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a52c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the function\n",
    "sample_mean_estimator(data = df, y = \"edgar_co2pc\", x = \"ones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b9831f",
   "metadata": {},
   "source": [
    "## Exercise 3: Write Nice Functions for your Estimators <a name=\"Exercise-3:-Write-Nice-Functions-for-your-Estimators\"></a>\n",
    "- Now we have one function for the sample mean estimator (with the fix). True Python coders would tell you that an efficient function should not have more than 5 lines max. So to have a **clean and efficient code**, what you should do is split this single function in multiple functions. \n",
    "- There are many ways to do this, but let's follow the logic of the function at hand:\n",
    "    - The first chunk of your function `sample_mean_estimator(data, y, x)` reads data and transforms it into matrixes. Take that chunk out and write a stand-alone function that transforms data into matrixes, which you can call `data_to_matrix(data, variab_name)` (your function has 2 arguments).\n",
    "    - Tips: you can also look at the code of the updated function `sample_mean_estimator(data, y, x)` below as a hint on what you are supposed to do here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d74bcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ...\n",
    "\n",
    "# function to transform panda series into vectors / matrices\n",
    "def data_to_matrix(data, variab_name):\n",
    "    \n",
    "    \"\"\" My Data to Matrix Function \"\"\"\n",
    "    \n",
    "    # store in matrixes\n",
    "    matrix = data.loc[:,variab_name].to_numpy()\n",
    "    \n",
    "    # make column vectors for arrays with less than 2 dimensions\n",
    "    if len(matrix.shape) == 1:\n",
    "        matrix = np.atleast_2d(matrix).T\n",
    "        \n",
    "    # return result\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772a72af",
   "metadata": {},
   "source": [
    "- Now your function `sample_mean_estimator(data, y, x)` only has the second chunk of code. We should re-define it so that it uses the function `data_to_matrix`. I give you the solution here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f069583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sample mean function\n",
    "def sample_mean_estimator(data, y, x):\n",
    "    \n",
    "    \"\"\" My Sample Mean Function \"\"\"\n",
    "    \n",
    "    # store in matrixes\n",
    "    ydata = data_to_matrix(data, variab_name = y)\n",
    "    xdata = data_to_matrix(data, variab_name = x)\n",
    "\n",
    "    # get sample mean\n",
    "    beta_hat = (inv(xdata.T @ xdata)) @ (xdata.T @ ydata)\n",
    "\n",
    "    # return\n",
    "    return float(beta_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccd040e",
   "metadata": {},
   "source": [
    "- Run this updated function to get the sample mean estimate of CO2 emissions per capita, and compare the results with a built in (\"canned\") function called `st.mean` using a logical operator (such as `np.allclose`). Tips:\n",
    "    - The formulas inside the function `st.mean` can be a bit different than our matrix formulas (you should look inside by using `??`). For this reason, the output might come out some decimals different, so the operator `==` will not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227adb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ...\n",
    "\n",
    "# estimate sample mean and store\n",
    "sample_mean = sample_mean_estimator(data = df, y = \"edgar_co2pc\", x = \"ones\")\n",
    "sample_mean\n",
    "\n",
    "# use canned method and compare\n",
    "sample_mean_canned = st.mean(df.loc[:,\"edgar_co2pc\"])\n",
    "print(sample_mean_canned)\n",
    "np.allclose(sample_mean, sample_mean_canned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56ff324",
   "metadata": {},
   "source": [
    "- Write a function for the sample variance estimator and obtain the sample variance estimate for CO2 emissions per capita. Tips:\n",
    "    - you should call this function `sample_variance_estimator(data, y, x, sample_mean)` (it has 4 arguments, where the 4th one is the outcome of your sample-mean function). \n",
    "    - This function should have a similar structure than the function `sample_mean_estimator`, for example, the first part should use the function `data_to_matrix`, and the second part should apply the matrix formulas of the sample-variance estimator.\n",
    "    - As an intermediate step to get the sample variance, you can get the residuals like this `resid = (ydata - np.dot(sample_mean, xdata))`, and then use them to get the sample variance (all from the matrix formulas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e433cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ...\n",
    "\n",
    "# write function for estimator for the standard error of the mean\n",
    "def sample_variance_estimator(data, y, x, sample_mean):\n",
    "\n",
    "    \"\"\" My Sample Variance Function \"\"\"\n",
    "    \n",
    "    # store in matrixes\n",
    "    ydata = data_to_matrix(data, variab_name = y)\n",
    "    xdata = data_to_matrix(data, variab_name = x)\n",
    "\n",
    "    # get params\n",
    "    N = len(ydata)\n",
    "    degrees_freedom = N-1\n",
    "\n",
    "    # get sample variance\n",
    "    resid = (ydata - np.dot(sample_mean, xdata))\n",
    "    sigma2_hat = (resid.T @ resid) /degrees_freedom\n",
    "    \n",
    "    # return\n",
    "    return float(sigma2_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478e8e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_variance = sample_variance_estimator(data = df, y = \"edgar_co2pc\", x = \"ones\", \n",
    "                                            sample_mean = sample_mean)\n",
    "sample_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d0e782",
   "metadata": {},
   "source": [
    "- Write a stand-alone function for the estimator Standard Error of the Mean (SEM) and obtain the SEM estimate for CO2 emissions per capita. Tips:\n",
    "    - you should call this function `sem_estimator(data, y, x, sample_mean)` (it has 4 arguments, where the 4th one is the outcome of your sample-mean function). \n",
    "    - It should have a similar structure than the function `sample_variance_estimator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eca2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ...\n",
    "\n",
    "# write function for estimator for the standard error of the mean\n",
    "def sem_estimator(data, y, x, sample_mean):\n",
    "\n",
    "    \"\"\" My SEM Estimator Function \"\"\"\n",
    "    \n",
    "    # store in matrixes\n",
    "    ydata = data_to_matrix(data, variab_name = y)\n",
    "    xdata = data_to_matrix(data, variab_name = X)\n",
    "\n",
    "    # get params\n",
    "    N = len(ydata)\n",
    "    degrees_freedom = N-1\n",
    "\n",
    "    # get sample variance\n",
    "    resid = (ydata - np.dot(sample_mean, xdata))\n",
    "    sigma2_hat = (resid.T @ resid) /degrees_freedom\n",
    "    \n",
    "    # get sem\n",
    "    sigma_hat = np.sqrt(sigma2_hat)\n",
    "    sem_hat = sigma_hat / np.sqrt(N)\n",
    "    \n",
    "    # return\n",
    "    return float(sem_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7106b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem = sem_estimator(data = df, y = \"edgar_co2pc\", x = \"ones\", sample_mean = sample_mean)\n",
    "sem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbf3b4b",
   "metadata": {},
   "source": [
    "## Exercise 4: Statistical Test with the Sample Mean <a name=\"Exercise-4:-Statistical-Test-with-the-Sample-Mean\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b958bb",
   "metadata": {},
   "source": [
    "- Let's now rely on the knowledge we have on **statistical tests** from the exercises of last class to write a function that does a one sample z-test on whether the estimate of the mean is significantly different from zero at the 5% level.\n",
    "- Remember? In the exercises, we have done (i) z-test with known variance, with z-score following a standard normal distribution, (ii) t-test with unknown variance, with t-statistic following a T-student distribution with $N-1$ degrees of freedom. \n",
    "- Thanks to the Central Limit Theorem (which we saw last time), we know that, as the sample size increases, the sample-mean estimator $\\hat{\\beta}$ always follows a normal distribution. It turns out that, thanks to the same theorem, as the sample size increases, the t-statistic also follows a standard normal distribution. Therefore, we can do a test with unknown variance using the functions and critical values of the normal distribution, such as `st.NormalDist()` and `stats.norm.ppf()`, rather than the functions and critical values of the t-student distribution (i.e. `stats.t.cdf()` and `stats.t.ppf()`).\n",
    "- Write a function that computes the z-score, p value, and the confidence interval for the sample mean and use it to test if the population mean of CO2 emissions per capita is different than zero, considering the estimate of the sample mean obtained above. Tips:\n",
    "    - Most of the code is in the exercises of last class\n",
    "    - You can call your function `one_sample_z_test(sample_mean, sem, beta_null = 0, significance_level = 0.05)` (4 arguments, with the first two being the obtained estimate for the sample mean and the obtained estimate for the standard error of the mean).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8659ac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write function for one sample t test statistic\n",
    "def one_sample_z_test(sample_mean, sem, beta_null = 0, significance_level = 0.05):\n",
    "    \n",
    "    \"\"\" My Z Test Function \"\"\"\n",
    "\n",
    "    # get z score\n",
    "    z_score = (sample_mean - beta_null) / sem\n",
    "\n",
    "    # get p value\n",
    "    lower_area = st.NormalDist().cdf(-abs(z_score))\n",
    "    upper_area = lower_area\n",
    "    p_value = lower_area + upper_area\n",
    "\n",
    "    # get confidence interval\n",
    "    alpha_inv = (1.0-significance_level)\n",
    "    q1 = (1+alpha_inv)/2\n",
    "    ci_critical = stats.norm.ppf(q1)\n",
    "    ci = (sample_mean-(ci_critical*sem), sample_mean+(ci_critical*sem))\n",
    "\n",
    "    # return results\n",
    "    return (z_score, p_value, ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c30e51",
   "metadata": {},
   "source": [
    "- Use the function to test if the mean of the population of CO2 emissions per capita is different from zero and compare the results with a built-in (\"canned\") function `stats.weightstats.ztest` from the `statsmodels` package, using a logical operator. Tips:\n",
    "    - Again you should be using `np.allclose` and not `==`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a4092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ...\n",
    "\n",
    "# run and store z test\n",
    "z_test = one_sample_z_test(sample_mean = sample_mean, sem = sem)\n",
    "z_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c32ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with canned methods\n",
    "import statsmodels\n",
    "z_test_canned = statsmodels.stats.weightstats.ztest(df[\"edgar_co2pc\"])\n",
    "print(z_test[0:2])\n",
    "print(z_test_canned)\n",
    "print(np.allclose(z_test[0:2], z_test_canned))\n",
    "\n",
    "z_test_ci_canned = statsmodels.stats.weightstats.zconfint(x1 = df[\"edgar_co2pc\"], x2=None, value=0, alpha=0.05)\n",
    "print(z_test[2])\n",
    "print(z_test_ci_canned)\n",
    "print(np.allclose(z_test[2], z_test_ci_canned))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3131271",
   "metadata": {},
   "source": [
    "- OK so to **recap** you have written functions for sample-mean, variance and standar-error estimators, and you have obtained estimates from all of these on a sample of CO2 emissions per capita at the country level. You have also run a statistical test to test whether the sample-mean estimate is significantly different than 0 at the 5% confidence level, using both t statistic / p value and confidence interval. \n",
    "- Use the functions developed above to display the results all together here below and comment them using the statistical \"phrasing\" you have learned. Tips:\n",
    "    - This should not take you more than 5 lines of code.\n",
    "    - The phrasing should be something along the lines of \"The sample mean for CO2 emissions per capita is ... and based on this estimate and our statistical test we can tell that the mean of the population is ...\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2e9ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# estimate sample mean and store\n",
    "sample_mean = sample_mean_estimator(data = df, y = \"edgar_co2pc\", x = \"ones\")\n",
    "\n",
    "# get p value of estimate being different than 0\n",
    "sem = sem_estimator(data = df, y = \"edgar_co2pc\", x = \"ones\", sample_mean = sample_mean)\n",
    "p_value = one_sample_z_test(sample_mean = sample_mean, sem = sem, beta_null = 0)[1]\n",
    "\n",
    "# print\n",
    "print(\"Estimate of Beta from Sample Mean Estimator:          \", round(sample_mean, 3))\n",
    "print(\"P-value for Estimate of Beta being different than 0:  \", round(p_value, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7c3784",
   "metadata": {},
   "source": [
    "Your answer here ...\n",
    "\n",
    "The coefficient 5.016 tells us that, on average, one person emits 5.016 of CO2 emissions per year. In addition, looking at the p-value of 0.000, we can say that this result is statistically significant at the 1% level (the p-value is smaller than 0.01). This means that, based on our sample and assumptions, we can be pretty darn sure that a person emits more than 0 tons of CO2 per year. The probability that we are wrong on this claim is 0.00000000000038846703634227 %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee41f04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
